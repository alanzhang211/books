# Apache Flink架构

第2章讨论了分布式流处理的重要概念，例如并行化，时间和状态。在本章中，我们对Flink的体系结构进行了高级介绍，并描述了Flink如何解决我们之前讨论过的流处理方面。特别是，我们解释了Flink的分布式架构，展示了它如何处理流应用程序中的时间和状态，并讨论其容错机制。本章提供了使用Apache Flink成功实现和操作高级流应用程序的相关背景信息。它将帮助您了解Flink的内部结构并推断流式应用程序的性能和行为。

## 系统架构
Flink是用于有状态并行数据流处理的分布式系统。 Flink设置由多个进程组成，这些进程通常分布在多台计算机上。分布式系统需要解决的常见挑战是群集中计算资源的分配和管理，流程协调，持久且高度可用的数据存储以及故障恢复。

Flink本身并没有实现所有这些功能。相反，它专注于其核心功能 - 分布式数据流处理 - 并利用现有的集群基础架构和服务。 Flink与集群资源管理器（如Apache Mesos，YARN和Kubernetes）很好地集成，但也可以配置为作为独立集群运行。 Flink不提供持久的分布式存储。相反，它利用了HDFS等分布式文件系统或S3等对象存储。对于高可用性设置中的领导者选举，Flink依赖于Apache ZooKeeper。

在本节中，我们将介绍Flink设置的不同组件以及它们如何相互交互以执行应用程序。我们讨论了两种不同的Flink应用程序部署方式以及每种方式分配和执行任务的方式。最后，我们解释了Flink高可用模式的工作原理。

### Flink设置组件
Flink设置由四个不同的组件组成，它们协同工作以执行流应用程序。这些组件是JobManager，ResourceManager，TaskManager和Dispatcher。由于Flink是在Java和Scala中实现的，因此所有组件都在Java虚拟机（JVM）上运行。每个组件都有以下职责：

**JobManager** 是控制单个应用程序执行的主进程 - 每个应用程序由不同的JobManager控制。 JobManager收到要执行的应用程序。该应用程序包含一个所谓的JobGraph，一个逻辑数据流图（参见“数据流编程简介”），以及一个捆绑所有必需的类，库和其他资源的JAR文件。 JobManager将JobGraph转换为名为ExecutionGraph的物理数据流图，其中包含可以并行执行的任务。 JobManager请求必要的资源（TaskManager插槽）以从ResourceManager执行任务。一旦它收到足够的TaskManager插槽，它就会将ExecutionGraph的任务分配给执行它们的TaskManagers。在执行期间，JobManager负责所有需要集中协调的操作，例如检查点的协调（请参阅“检查点，保存点和状态恢复”）。

Flink为不同的环境和资源提管理器（如YARN，Mesos，Kubernetes和独立部署）提供​​多个ResourceManagers。 ResourceManager负责管理Flink的处理资源单元TaskManager插槽。当JobManager请求TaskManager插槽时，ResourceManager会指示具有空闲插槽的TaskManager将它们提供给JobManager。如果ResourceManager没有足够的插槽来满足JobManager的请求，则ResourceManager可以与资源提供者通信以配置启动TaskManager进程的容器。 ResourceManager还负责终止空闲的TaskManagers以释放计算资源。

**TaskManagers** 是Flink的工作进程。通常，在Flink设置中运行多个TaskManagers。每个TaskManager提供一定数量的插槽。插槽数限制了TaskManager可以执行的任务数。启动后，TaskManager将其插槽注册到ResourceManager。在ResourceManager的指示下，TaskManager将一个或多个插槽提供给JobManager。然后，JobManager可以将任务分配给插槽以执行它们。在执行期间，TaskManager与运行同一应用程序任务的其他TaskManagers交换数据。 “任务执行”中讨论了任务的执行和插槽的概念。

**Dispatcher** 调度程序跨作业执行运行，并提供REST接口以提交执行应用程序。一旦提交了一个应用程序执行，它就会启动一个JobManager并交出该应用程序。 REST接口使调度程序可以作为防火墙后面的集群的HTTP入口点。调度程序还运行Web仪表板以提供有关作业执行的信息。根据应用程序的提交执行方式（在“应用程序部署”中讨论），可能不需要调度程序。

图3-1显示了在提交执行应用程序时Flink的组件如何相互交互。

![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-1.png)

> 注意图3-1是一个高级草图，用于可视化应用程序组件的职责和交互。根据环境（YARN，Mesos，Kubernetes，独立集群），可以省略某些步骤，或者可以在同一JVM进程中运行组件。例如，在独立设置 - 没有资源提供者的设置中 -  ResourceManager只能分发可用TaskManagers的插槽，并且无法自己启动新的TaskManagers。在“部署模式”中，我们将讨论如何为不同的环境设置和配置Flink。


###  程序部署
Flink程序可以通过2中不同的方式部署。

框架风格
在此模式下，Flink应用程序打包到JAR文件中，并由客户端提交给正在运行的服务。该服务可以是Flink Dispatcher，Flink JobManager或YARN的ResourceManager。在任何情况下，都有一个服务运行，它接受Flink应用程序并确保它被执行。如果应用程序已提交给JobManager，它会立即开始执行该应用程序。如果应用程序已提交给Dispatcher或YARN ResourceManager，它将启动JobManager并移交应用程序，JobManager将开始执行该应用程序。

库风格
在此模式下，Flink应用程序捆绑在特定于应用程序的容器映像中，例如Docker映像。该图像还包括运行JobManager和ResourceManager的代码。从映像启动容器时，它会自动启动ResourceManager和JobManager并提交捆绑的作业以供执行。第二个与作业无关的映像用于部署TaskManager容器。从此映像启动的容器会自动启动TaskManager，该TaskManager连接到ResourceManager并注册其插槽。通常，外部资源管理器（如Kubernetes）负责启动映像并确保在发生故障时重新启动容器。

框架风格遵循通过客户端向正在运行的服务提交应用程序（或查询）的传统方法。在库风格中，没有Flink服务。相反，Flink与容器映像中的应用程序一起捆绑为库。此部署模对于微服务体系结构是常见的。我们将在“运行和管理流应用程序”中更详细地讨论应用程序部署的主题。

### 任务执行
TaskManager可以同时执行多个任务。这些任务可以是同一运算符的子任务（数据并行），不同的运算符（任务并行），甚至是不同的应用程序（作业并行）。 TaskManager提供一定数量的处理槽来控制它能够同时执行的任务数量。处理槽可以执行应用程序的每个操作符的一个应用程序 - 一个并行任务。图3-2显示了TaskManagers，插槽，任务和运营商之间的关系。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-2.png)

在图3-2的左侧，您可以看到JobGraph  - 应用程序的非平行表示 - 由五个运算符组成。运算符A和C是源，运算符E是接收器。运算符C和E具有两个并行性。其他操作符有四个并行度。由于最大运算符并行度为4，因此应用程序需要至少执行四个可用处理槽。给定两个具有两个处理槽的TaskManagers，满足此要求。 JobManager将JobGraph跨越到ExecutionGraph并将任务分配给四个可用插槽。具有四个并行性的运算符的任务被分配给每个时隙。操作符C和E的两个任务分别分配给插槽1.1和2.1以及插槽1.2和2.2。将任务调度为切片到插槽具有以下优点：许多任务在TaskManager上共存，这意味着他们可以在同一进程内有效地交换数据而无需访问网络。但是，过多的共存任务也会使TaskManager过载并导致性能下降。在“控制任务调度”中，我们讨论如何控制任务的调度。

TaskManager在同一JVM进程中执行多线程任务。线程比单独的进程更轻量级，并且具有更低的通信成本，但不会严格地将任务彼此隔离。因此，单个行为不当的任务可以杀死整个TaskManager进程以及在其上运行的所有任务。通过为每个TaskManager仅配置一个插槽，您可以跨TaskManagers隔离应用程序。通过利用TaskManager内部的线程并行性并为每个主机部署多个TaskManager进程，Flink提供了很大的灵活性，可以在部署应用程序时权衡性能和资源隔离。我们将在第9章详细讨论Flink集群的配置和设置。

### 高可用设置
流应用程序通常设计为24/7运行。因此，即使涉及的进程失败，它们的执行也不会停止是很重要的。要从故障中恢复，系统首先需要重新启动失败的进程，然后重新启动应用程序并恢复其状态。在本节中，您将了解Flink如何重新启动失败的进程。 “从一致的检查点恢复”中描述了恢复应用程序的状态。

### Task管理器失败
如前所述，Flink需要足够数量的处理槽以执行应用程序的所有任务。给定Flink设置，其中四个TaskManagers每个提供两个插槽，可以执行流应用程序，最大并行度为8。如果其中一个TaskManagers失败，可用插槽的数量将减少到六个。在这种情况下，JobManager将要求ResourceManager提供更多处理槽。如果这不可能 —— 例如，因为应用程序在独立群集中运行 -  JobManager无法重新启动应用程序，直到有足够的插槽可用。应用程序的重启策略决定JobManager重新启动应用程序的频率以及重新启动尝试之间等待的时间。

### Job管理器失败
比TaskManager失败更具挑战性的问题是JobManager失败。 JobManager控制流应用程序的执行并保留有关其执行的元数据，例如：指向已完成检查点的指针。如果负责的JobManager进程消失，则流应用程序无法继续处理。这使得JobManager成为Flink中应用程序的单点故障。为了解决这个问题，Flink支持高可用性模式，以便在原始JobManager消失的情况下将作业的职责和元数据迁移到另一个JobManager。

Flink的高可用性模式基于Apache ZooKeeper，这是一个需要协调和共识的分布式服务系统。 Flink使用ZooKeeper进行领导者选举，并使用高可用性和持久性数据存储。在高可用性模式下运行时，JobManager将JobGraph和所有必需的元数据（例如应用程序的JAR文件）写入远程持久存储系统。此外，JobManager将指向存储位置的指针写入ZooKeeper的数据存储区。在执行应用程序期间，JobManager接收各个任务检查点的状态句柄（存储位置）。完成检查点后 - 当所有任务已成功将其状态写入远程存储器时 -  JobManager将状态句柄写入远程存储器，并将指向此位置的指针写入ZooKeeper。因此，从JobManager故障中恢复所需的所有数据都存储在远程存储器中，ZooKeeper保存指向存储位置的指针。图3-3说明了这种设计。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-3.png)

当JobManager失败时，属于其应用程序的所有任务都将自动取消。新JobManager接管故障主站工作，需要执行以下步骤：
从ZooKeeper请求存储位置，然后从远程存储器获取JobGraph，JAR文件和应用程序的最后一个检查点的状态句柄。
从ResourceManager请求处理插槽以继续执行应用程序。
重启应用，并将所有的任务状态重置为上一次完成的检查点。
在容器环境（例如Kubernetes）中将应用程序作为库部署运行时，容器编排服务通常会自动重新启动失败的JobManager或TaskManager容器。在YARN或Mesos上运行时，Flink的剩余进程会触发JobManager或TaskManager进程的重启。在独立群集中运行时，Flink不提供重新启动失败进程的工具。因此，运行可以接管失败进程工作的备用JobManagers和TaskManagers会很有用。我们稍后将在“高可用性设置”中讨论高可用性Flink设置的配置。

### Flink中的数据传输
正在运行的应用程序的任务是不断交换数据。 TaskManagers负责将数据从发送任务发送到接收任务。 TaskManager的网络组件在发送之前收集缓冲区中的记录，即记录不是逐个发送而是分批到缓冲区中。该技术对于有效使用网络资源和实现高吞吐量是至关重要的。该机制类似于网络或磁盘I / O协议中使用的缓冲技术。

> 请注意，缓冲区中的传输记录确实意味着Flink的处理模型基于微批处理的。

每个TaskManager都有一个网络缓冲池（默认大小为32 KB），用于发送和接收数据。如果发送方和接收方任务在单独的TaskManager进程中运行，则它们通过操作系统的网络堆栈进行通信。流应用程序需要以流水线方式交换数据 - 每对TaskManagers都维护一个永久的TCP连接来交换数据。使用shuffle连接模式，每个发送方任务都需要能够向每个接收任务发送数据。 TaskManager需要为每个接收任务提供一个专用网络缓冲区，其任务需要将任何任务发送到该任务。图3-4显示了这种架构
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-4.png)

如图3-4所示，四个发送器任务中的每一个都需要至少四个网络缓冲区来向每个接收器任务发送数据，每个接收器任务至少需要四个缓冲区来接收数据。需要发送到另一个TaskManager的缓冲区通过同一网络连接进行多路复用。为了实现流畅的流水线数据交换，TaskManager必须能够提供足够的缓冲区来同时为所有传出和传入连接提供服务。通过shuffle或广播连接，每个发送任务都需要一个缓冲区用于每个接收任务;所需缓冲区的数量与所涉及的运算符的任务数量成二次方。 Flink的网络缓冲区默认配置足以满足中小型设置的需要。对于较大的设置，您需要按照“主内存和网络缓冲区”中的说明调整配置。

当发送方任务和接收方任务在同一个TaskManager进程中运行时，发送方任务将输出记录序列化为字节缓冲区，并在填充后将缓冲区放入队列中。接收任务从队列中获取缓冲区并反序列化传入的记录。因此，在同一TaskManager上运行的任务之间的数据传输不会导致网络通信。

Flink采用不同的技术来降低任务之间的通信成本。在以下部分中，我们将简要讨论基于信用的流量控制和任务链。

### 基于信用的流量控制
通过网络连接发送单个记录是低效的并且导致显着的开销。需要缓冲以充分利用网络连接的带宽。在流处理的上下文中，缓冲的一个缺点是它增加了延迟，因为记录被收集在缓冲区中而不是立即发送。

Flink实现了基于信用的流量控制机制，其工作原理如下。接收任务向发送任务授予一些信用，发送任务是保留用于接收其数据的网络缓冲区的数量。一旦发送方收到信用通知，它就会发送与授予的缓冲区一样多的缓冲区 - 填充并准备发运的网络缓冲区的数量。接收方使用保留的缓冲区处理已发送的数据，并使用发送方的积压大小为其所有连接的发送方确定下一个信用额度的优先顺序。

基于信用的流量控制可以减少延迟，因为一旦接收方有足够的资源接收数据，发送方就可以发送数据。此外，在数据分布偏差的情况下，它是一种有效的机制来分配网络资源，因为信用是根据发送者的积压大小授予的。因此，基于信用的流量控制是Flink实现高吞吐量和低延迟的重要组成部分。

### 任务链
Flink采用称为任务链的优化技术，可以在某些条件下减少本地通信的开销。为了满足任务链的要求，必须为两个或多个操作算子配置相同的并行性并通过本地前向信道连接。图3-5中所示的操作算子管道满足了这些要求。它由三个运算符组成，这些运算符都配置为两个任务并行，并与本地前向连接相连。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-5.png)

图3-6描述了如何使用任务链执行管道。运算符的函数被融合到由单个线程执行的单个任务中。由函数生成的记录通过简单的方法调用分别移交给下一个函数。因此，在函数之间传递记录基本上没有序列化和通信成本。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-6.png)

任务链可以显着降低本地任务之间的通信成本，但也有一些情况是在没有链接的情况下执行管道是有意义的。例如，打破链接任务的长管道或将链分成两个任务以将昂贵的功能安排到不同的插槽是有意义的。图3-7显示了在没有任务链的情况下执行的相同管道。所有功能都由在专用线程中运行的单个任务进行评估。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-7.png)


Flink中默认启用任务链。在“控制任务链”中，我们将展示如何禁用应用程序的任务链以及如何控制各个运算符的链接行为。

事件事件处理
在“时间语义学”中，我们强调了时间语义对流处理应用程序的重要性，并解释了处理时间和事件时间之间的差异。虽然处理时间很容易理解，因为它基于处理机器的本地时间，但它会产生一些任意的，不一致的和不可重现的结果。相反，事件时间语义产生可重现且一致的结果，这是许多流处理用例的硬性要求。但是，与具有处理时语义的应用程序相比，事件时间应用程序需要额外的配置。此外，支持事件时间的流处理器的内部比纯粹在处理时间中操作的系统的内部更复杂。

Flink为常见的事件处理操作提供了直观且易于使用的原语，但也公开了丰富的API，进而通过自定义运算符实现更高级的事件时间应用程序。充分了解Flink的内部时间处理通常对于此类高级应用程序是有帮助的，有时也是必需的。前一章介绍了Flink利用提供事件时间语义的两个概念：记录时间戳和水印。在下文中，我们将描述Flink如何在内部实现和处理时间戳和水印，以支持具有事件时间语义的流应用程序。

### 时间戳
当Flink以事件时间模式处理数据流时，它会根据记录的时间戳评估基于时间的运算符。例如，时间窗口操作符根据其关联的时间戳为窗口分配记录。 Flink将时间戳编码为16字节的Long值，并将它们作为元数据附加到记录中。它的内置运算符将Long值解释为具有毫秒精度的Unix时间戳 - 自1970-01-01-00：00：00000以来的毫秒数。但是，自定义运算符可以有自己的解释，例如，可以将精度调整为微秒。

### 水印
除了记录时间戳之外，Flink事件时间应用程序还必须提供水印。水印用于在事件时间应用程序中导出每个任务的当前事件时间。基于时间的运算符使用此时间来触发计算并取得进展。例如，时间窗口任务最终确定窗口计算，并在任务事件。

在Flink中，水印被实现为将时间戳保存为Long值的特殊记录。水印在带有注释时间戳的常规记录流中流动，如图3-8所示。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-8.png)

### 水印有2个基本属性
它们必须单调增加，以确保任务的事件时钟正在进行而不是后退.
它们与记录时间戳有关。带有时间戳T的水印表示所有后续记录的时间戳应> T.

第二个属性用于处理具有无序记录时间戳的流，例如图3-8中带有时间戳3和5的记录。基于时间的运算符的任务收集和处理具有可能无序时间戳的记录，并且当它们的事件时钟（由接收的水印提前）指示不再需要具有相关时间戳的记录时，最终确定计算。当任务接收到违反水印属性并且具有比先前接收的水印更小的时间戳的记录时，可能是它所属的计算已经完成。这些记录称为后期记录。 Flink提供了处理延迟记录的不同方法，这些方法在“处理延迟数据”中进行了讨论。

水印的一个有趣特性是它们允许应用程序控制结果的完整性和延迟。与记录时间戳非常接近的水印会导致处理延迟低，因为任务只会在完成计算之前暂时等待更多记录到达。同时，结果完整性可能会受到影响，因为相关记录可能不会包含在结果中，并且会被视为延迟记录。相反，非常保守的水印会增加处理延迟，但会提高结果的完整性。

### 水印传播和事件时间
在本节中，我们将讨论运算符如何处理水印。 Flink将水印实现为由操作算子任务接收和发出的特殊记录。任务具有维护计时器的内部时间服务，并在收到水印时激活。任务可以在计时器服务中注册计时器，以在将来的特定时间点执行计算。例如，窗口操作符为每个活动窗口注册一个计时器，当事件时间超过窗口的结束时间时，它会清除窗口的状态。

当任务收到水印时，会执行下面的操作：
1. 任务会根据水印的时间戳更新其内部事件时钟。
2. 任务的时间服务识别时间小于更新的事件时间的所有计时器。对于每个过期的计时器，该任务调用一个可以执行计算并发出记录的回调函数。
3. 任务通过更新事件时间发出水印。

> Flink通过DataStream API限制对时间戳或水印的访问。函数无法读取或修改记录时间戳和水印，除了过程函数，它可以读取当前处理的记录的时间戳，请求操作员的当前事件时间，以及注册定时器。这些函数都没有公开API来设置发出记录的时间戳，操纵任务的事件时钟或发出水印。相反，基于时间的DataStream操作员任务配置发出的记录的时间戳，以确保它们与发出的水印正确对齐。例如，时窗操作员任务将窗口的结束时间附加到窗口计算发出的所有记录的时间戳之前，其发出具有触发窗口计算的时间戳的水印。

现在让我们更详细地解释一个任务如何发出水印并在接收到新水印时更新其事件时钟。正如您在“数据并行和任务并行”中所看到的，Flink将数据流拆分为分区，并通过单独的运算符任务并行处理每个分区。每个分区都是带时间戳的记录和水印。根据操作算子与其前任或后继操作算子的连接方式，其任务可以从一个或多个输入分区接收记录和水印，并将记录和水印发送到一个或多个输出分区。在下文中，我们将详细描述任务如何向多个输出任务发出水印，以及它如何从其从输入任务接收的水印中提升其事件时钟。

任务为每个输入分区维护分区水印。当它从分区接收到水印时，它将相应的分区水印更新为接收值和当前值的最大值。随后，任务将其事件时钟更新为所有分区水印中的最小值。如果事件时间时钟前进，则任务处理所有触发的定时器，并最终通过向所有连接的输出分区发出相应的水印，将其新的事件时间广播到所有下游任务。

图3-9显示了具有四个输入分区和三个输出分区的任务如何接收水印，更新其分区水印和事件时钟，以及发出水印。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-9.png)

具有两个或更多输入流的运算符（例如Union或CoFlatMap）的任务（参见“多流转换”）也将它们的事件时钟计算为所有分区水印的最小值 - 它们不区分不同输入流的分区水印。因此，基于相同的事件时间时钟处理两个输入的记录。如果应用程序的各个输入流的事件时间未对齐，则此行为可能会导致问题。

Flink的水印处理和传播算法可确保操作算子任务发出正确对齐的带时间戳记录和水印。但是，它依赖于所有分区不断提供增加的水印的事实。一旦一个分区没有前进其水印或变得完全空闲并且不发送任何记录或水印，任务的事件时间时钟将不会前进并且任务的定时器将不会触发。对于依赖于提前时钟执行计算并清理其状态的基于时间的运算符，这种情况可能是有问题的。因此，如果任务没有以规则的间隔从所有输入任务接收新的水印，则基于时间的操作员的处理等待时间和状态大小可以显着增加。

对于具有两个输入流的运算符，出现类似的效果，其中水印显着不同。具有两个输入流的任务的事件时间时钟将对应于较慢流的水印，并且通常较快流的记录或中间结果被缓冲在状态直到事件时间时钟允许处理它们。

### 时间戳分配和水印生成
到目前为止，我们已经解释了Flink的时间戳和水印以及它们如何在内部处理。但是，我们还没有讨论它们的来源。通常在流应用程序摄取流时，分配和生成时间戳和水印。由于时间戳的选择是特定于应用程序的，并且水印取决于流的时间戳和特征，因此应用程序必须明确分配时间戳并生成水印。 Flink DataStream应用程序可以通过三种方式为流分配时间戳并生成水印。
在源处：当流被提取到应用程序中时，可以由SourceFunction分配和生成时间戳和水印。源函数发出记录流。记录可以与相关的时间戳一起发出，水印可以作为特殊记录在任何时间点发出。如果源函数（临时）不再发出水印，则它可以声明自己空闲。 Flink将从后续运算符的水印计算中排除空闲源函数生成的流分区。如前所述，源的空闲机制可用于解决不推进水印的问题。源函数在“实现自定义源函数”中有更详细的讨论。
定期分配器：DataStream API提供一个名为AssignerWithPeriodicWatermarks的用户定义函数，该函数从每个记录中提取时间戳，并定期查询当前水印。提取的时间戳被分配给相应的记录，并且查询的水印被摄取到流中。此功能将在“分配时间戳和生成水印”中讨论。
标点分配器：AssignerWithPunctuatedWatermarks是另一个用户定义的函数，它从每个记录中提取时间戳。它可用于生成在特殊输入记录中编码的水印。与AssignerWithPeriodicWatermarks函数相比，此函数可以 - 但不需要从每个记录中提取水印。我们还在“分配时间戳和生成水印”中详细讨论了这个功能。

用户定义的时间戳分配函数通常尽可能靠近源操作符应用，因为在操作符处理完记录及其时间戳之后，很难对其进行推理。这也是在流应用程序中间覆盖现有时间戳和水印不是一个好方式的原因，尽管这可以通过用户定义的函数实现。

## 状态管理
在第2章中，我们指出大多数流应用程序都是有状态的。许多操作算子不断地读取和更新某种状态，例如：在窗口中收集的记录，读取输入源的位置，或者诸如机器学习模型的定制的，特定于应用的操作算子状态。 Flink处理所有状态 - 无论内置或用户定义的运算符 - 都相同。在本节中，我们将讨论Flink支持的不同类型的状态。我们将解释状态后端如何存储和维护状态，以及如何通过重新分配状态来扩展状态应用程序。

通常，由任务维护并用于计算函数结果的所有数据都属于任务的状态。您可以将状态视为由任务的业务逻辑访问的本地或实例变量。图3-10显示了任务与其状态之间的典型交互。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-10.png)

任务接收一些输入数据。在处理数据时，任务可以读取和更新其状态，并根据其输入数据和状态计算其结果。一个简单的例子是一个连续计算它接收的记录数量的任务。当任务收到新记录时，它会访问状态以获取当前计数，递增计数，更新状态并发出新计数。

用于读取和写入状态的应用程序逻辑通常很简单。然而，有效和可靠的状态管理更具挑战性。这包括处理非常大的状态，可能超过内存，并确保在发生故障时不会丢失任何状态。 Flink负责处理与状态一致性，故障处理以及高效存储和访问相关的所有问题，以便开发人员可以专注于其应用程序的逻辑。

在Flink中，状态始终与特定运算符相关联。为了使Flink的运行时了解运算符的状态，运算符需要注册其状态。有两种类型的状态，操作符状态和键控状态，可以从不同的范围访问，并在以下部分中讨论。

### 操作符状态
操作符状态的范围限定为操作符任务。这意味着由同一并行任务处理的所有记录都可以访问相同的状态。操作符状态不能由相同或不同操作符的另一个任务访问。图3-11显示了任务如何访问操作符状态。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-11.png)

Flink为操作符状态提供三个基元：
列表状态：
将状态表示为条目列表。
联盟状态列表：
将状态表示为条目列表。但它与常规列表状态的区别在于如何在发生故障或从保存点启动应用程序时还原它。我们将在本章后面讨论这种差异。
广播状态：
专为操作符的每项任务的状态相同的特殊情况而设计。在检查点和重新调整操作符时，可以利用此属性。这两个方面将在本章的后面部分讨论。

### 键控状态
根据在操作符输入流的记录中定义的键来维护和访问键控状态。 Flink为每个键值维护一个状态实例，并将具有相同键的所有记录分区到维护此键的状态的操作符任务。当任务处理记录时，它会自动将状态访问范围限定为当前记录的键。因此，具有相同密钥的所有记录都访问相同的状态。图3-12显示了任务如何与键控状态进行交互。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-12.png)

您可以将键控状态视为在操作符的所有并行任务上对键进行分区（或分片）的键值映射。 Flink为键控状态提供不同的基元，用于确定为此分布式键值映射中的每个键存储的值的类型。我们将简要讨论最常见的键控状态原语。

**值状态**：
存储每个键的任意类型的单个值。复杂数据结构也可以存储为值状态。
**列表状态**：
存储每个键的值列表。列表条目可以是任意类型。
**Map状态:**
存储每个键的键值映射。地图的关键和价值可以是任意类型。
状态原语将状态结构暴露给Flink并实现更有效的状态访问。它们将在“在RuntimeContext中声明键控状态”中进一步讨论。

### 状态后端
有状态运算符的任务通常为每个传入记录读取和更新其状态。由于有效的状态访问对于处理低延迟的记录至关重要，因此每个并行任务在本地维护其状态以确保快速状态访问。存储，访问和维护状态的确切方式由称为状态后端的可插入组件决定。状态后端负责两件事：本地状态管理和远程位置的检查点状态。

对于本地状态管理，状态后端存储所有键控状态，并确保所有访问都正确地限定为当前键。 Flink提供状态后端，将后台状态作为存储在JVM堆上的内存数据结构中的对象进行管理。另一个状态后端序列化状态对象并将它们放入RocksDB，后者将它们写入本地硬盘。虽然第一个选项提供非常快速的状态访问，但它受内存大小的限制。访问RocksDB状态后端存储的状态较慢，但其状态可能会变得非常大。

状态检查点很重要，因为Flink是一个分布式系统，状态只在本地维护。 TaskManager进程（以及使用它的所有任务在其上运行）可能在任何时间点失败。因此，其存储必须被视为易失性。状态后端负责将任务状态检查点指向远程持久存储。用于检查点的远程存储器可以是分布式文件系统或数据库系统。状态后端在状态检查点方面有所不同。例如，RocksDB状态后端支持增量检查点，这可以显着减少非常大的状态大小的检查点开销

我们将在“选择状态后端”中更详细地讨论不同的状态后端及其优缺点。

### 扩展有状态运算符
流应用程序的一个常见要求是调整运算符的并行性，因为输入速率会增加或减少。虽然扩展无状态运算符是微不足道的，但更改有状态运算符的并行性更具挑战性，因为它们的状态需要重新分区并分配给更多或更少的并行任务。 Flink支持四种模式来扩展不同类型的状态。

具有键控状态的操作符通过将键重新分区为更少或更多任务来缩放。但是，为了提高任务之间必要的状态转移效率，Flink不会重新分配单个密钥。相反，Flink在所谓的密钥组中组织密钥。密钥组是密钥的分区和Flink为任务分配密钥的方式。图3- 13显示了如何在密钥组中重新分区键控状态。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-13.png)

具有操作符列表状态的操作符通过重新分配列表条目来进行缩放。从概念上讲，收集所有并行操作符任务的列表条目并将其均匀地重新分配给更少或更多的任务。如果列表条目少于运算符的新并行度，则某些任务将以空状态开始。图3-14显示了操作符列表状态的重新分配。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-14.png)

具有操作符联合列表状态的操作符通过向每个任务广播状态条目的完整列表来缩放。然后，任务可以选择要使用的条目和要丢弃的条目。图3-15显示了如何重新分配运算符联合列表状态。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-15.png)

通过将状态复制到新任务来扩展具有操作员广播状态的操作符。这是有效的，因为广播状态确保所有任务具有相同的状态。在降尺度的情况下，简单地取消多余任务，因为状态已经被复制并且不会丢失。图3-16显示了操作符广播状态的重新分配。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-16.png)

## 检查点，保存点和状态恢复
Flink是一个分布式数据处理系统，因此必须处理故障，例如被杀死的进程，故障的机器和中断的网络连接。由于任务在本地维护其状态，因此Flink必须确保此状态不会丢失并在发生故障时保持一致。

在本节中，我们将介绍Flink的检查点和恢复机制，以保证一次性状态的一致性。 我们还讨论了Flink独特的保存点功能，这是一种“瑞士军刀”式工具，可以解决许多操作流的挑战。

### 一致的检查点
Flink的恢复机制基于应用程序状态的一致检查点。 状态流应用程序的一致检查点是在所有任务处理完全相同的输入时的每个任务的状态的副本。 这可以通过查看采用应用程序的一致检查点的朴素算法的步骤来解释。 这个简单算法的步骤是：
1. 暂停所有输入流的获取。
2. 等待所有正在进行的数据完全处理，这意味着所有任务都处理了所有输入数据。
3. 通过将每个任务的状态复制到远程持久存储来获取检查点。 当所有任务完成副本后，检查点即完成。
4. 恢复所有数据流的获取。

> 请注意，Flink没有实现这种简单的机制。 我们将在本节后面介绍Flink更复杂的检查点算法。

图3-17显示了简单应用程序的一致检查点。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-17.png)

该应用程序具有单个源任务，该任务消耗数量增加的流-1,2,3等。 数字流被划分为偶数和奇数的流。 求和运算符的两个任务计算所有偶数和奇数的运行总和。 源任务将其输入流的当前偏移量存储为状态。 求和任务将当前和值保持为状态。 在图3-17中，当输入偏移量为5时，Flink采用了检查点，总和为6和9。

### 从一致的检查点恢复
在执行流应用程序期间，Flink会定期检查应用程序状态的一致检查点。 如果发生故障，Flink将使用最新的检查点来一致地恢复应用程序的状态并重新启动处理。 图3-18显示了恢复过程。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-18.png)

应用通过以下3个步进行恢复：
1. 重启整个应用。
2. 将所有有状态任务的状态重置为最新检查点。
3. 恢复所有任务的处理。

这种检查点和恢复机制可以为应用程序状态提供准确的一致性，因为所有操作符都检查点并恢复其所有状态，并且所有输入流都被重置到检查点被占用时消耗的位置。 数据源是否可以重置其输入流取决于其实现以及从中使用流的外部系统或接口。 例如，像Apache Kafka这样的事件日志可以提供来自流的先前偏移的记录。 相反，从套接字消耗的流不能被重置，因为套接字一旦被消耗就丢弃数据。 因此，如果所有输入流都被可重置数据源消耗，则应用程序只能在一次性状态一致性下运行。

从检查点重新启动应用程序后，其内部状态与检查点完成时的状态完全相同。 然后它开始使用和处理在检查点和故障之间处理的所有数据。 虽然这意味着Flink处理一些消息两次（在故障之前和之后），但该机制仍然实现了一次性状态一致性，因为所有操作符的状态都被重置为尚未看到此数据的点。

我们必须指出，Flink的检查点和恢复机制仅重置流应用程序的内部状态。 根据应用程序的接收器操作符，在恢复期间，某些结果记录可能会多次发送到下游系统，例如事件日志，文件系统或数据库。 对于某些存储系统，Flink提供了具有精确一次输出功能的接收器功能，例如，通过在检查点完成时提交发出的记录。 适用于许多存储系统的另一种方法是幂等更新。 在“应用程序一致性保证”中详细讨论了端到端一次性应用程序和解决这些问题的方法的挑战。

### Flink的检查点算法
Flink的恢复机制基于一致的应用程序检查点。 从流媒体应用程序中获取检查点以暂停、检查点和恢复应用程序的简明方法对于由于其“stop-the-world”行为而具有中等延迟要求的应用程序而言并不实用。 相反，Flink基于Chandy-Lamport算法实现了分布式快照的检查点。 该算法不会暂停整个应用程序，而是将检查点与处理分离，以便某些任务继续处理，而其他任务则保持其状态。 在下文中，我们将解释此算法的工作原理。

Flink的检查点算法使用一种称为检查点障碍的特殊记录。 与水印类似，检查点障碍由源操作算子注入常规记录流，不能超过或被其他记录传递。 检查点屏障携带检查点ID以标识其所属的检查点，并在逻辑上将流分成两部分。 由于屏障之前的记录而导致的所有状态修改都包含在屏障的检查点中，并且由于屏障之后的记录而导致的所有修改都包含在稍后的检查点中。

我们使用简单流应用程序的示例逐步解释算法。 该应用程序由两个源任务组成，每个任务都消耗一个数量不断增加的流。 源任务的输出被划分为偶数和奇数的流。 每个分区由一个任务处理，该任务计算所有收到的数字的总和，并将更新的总和转发给接收器。 该应用程序如图3-19所示。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-19.png)

JobManager通过向每个数据源任务发送带有新检查点ID的消息来启动检查点，如图3-20所示。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-20.png)

当数据源任务收到消息时，它会暂停发出记录，在状态后端触发其本地状态的检查点，并通过所有传出流分区以检查点ID广播检查点障碍。 状态后端在状态检查点完成后通知任务，任务确认JobManager上的检查点。 在发出所有障碍后，来源继续其常规操作。 通过将屏障注入其输出流，源函数定义了检查点所在的流位置。 图3-21显示了两个源任务检查其本地状态和发出检查点障碍后的流应用程序。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-21.png)


源任务发出的检查点障碍将传送到连接的任务。 与水印类似，检查点障碍被广播到所有连接的并行任务，以确保每个任务从其每个输入流中接收屏障。 当新检查点的任务障碍时，它等待检查点的所有输入分区的障碍到达。 在等待时，它会继续处理尚未提供障碍的流分区中的记录。 到达转发屏障的分区的记录已无法处理和缓冲。 等待所有障碍到达的过程称为障碍对齐，如图3-22所示。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-22.png)

一旦任务从其所有输入分区收到障碍，它就会在状态后端启动一个检查点，并向所有下游连接任务广播检查点屏障，如图3-23所示。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-23.png)

一旦发出所有检查点障碍，任务就开始处理缓冲的记录。 在发出所有缓冲记录之后，任务继续处理其输入流。 此时，图3-24显示了应用程序。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-24.png)

最终，检查点屏障到达接收器任务。 当接收器任务接收到屏障时，它执行屏障对齐，检查点自己的状态，并确认接收到JobManager的屏障。 一旦从应用程序的所有任务收到检查点确认，JobManager就会将应用程序的检查点记录为已完成。 图3-25显示了检查点算法的最后一步。 完成的检查点可用于从故障中恢复应用程序，如前所述。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-25.png)

### 检查点的性能影响
Flink的检查点算法可以在不停止整个应用程序的情况下从流应用程序生成一致的分布式检查点。 但是，它可能会增加应用程序的处理延迟。 Flink实施的调整可以减轻某些条件下的性能影响。

当任务检查其状态时，它被阻止并且其输入被缓冲。由于状态可能变得非常大并且检查点需要通过网络将数据写入远程存储系统，因此对于对延迟敏感的应用程序而言，检查点可能很容易花费几秒到几分钟。在Flink的设计中，状态后端负责执行检查点。如何复制任务的状态取决于状态后端的实现。例如，FileSystem状态后端和RocksDB状态后端支持异步检查点。触发检查点时，状态后端会创建状态的本地副本。本地副本完成后，任务将继续其常规处理。后台线程将本地快照异步复制到远程存储，并在完成检查点后通知任务。异步检查点显着减少了任务继续处理数据之前的时间。此外，RocksDB状态后端还具有增量检查点，可减少要传输的数据量。

减少检查点算法对处理延迟的影响的另一种技术是调整屏障对齐步骤。 对于需要非常低延迟并且可以容忍至少一次状态保证的应用程序，Flink可以配置为在缓冲区对齐期间处理所有到达的记录，而不是缓冲已经到达屏障的那些记录。 一旦检查点的所有障碍到达，操作符就会检查状态，现在可能还包括由通常属于下一个检查点的记录引起的修改。 如果发生故障，将再次处理这些记录，这意味着检查点至少提供一次而不是完全一次的一致性保证。

### 保存点
Flink的恢复算法基于状态检查点。 根据可配置的策略定期检查并自动丢弃检查点。 由于检查点的目的是确保在发生故障时可以重新启动应用程序，因此在明确取消应用程序时会删除它们。 但是，应用程序状态的一致快照可用于除故障恢复之外的更多功能。

保存点是Flink最有价值和独特的功能之一。 原则上，使用与检查点相同的算法创建保存点，因此基本上是具有一些额外元数据的检查点。 Flink不会自动获取保存点，因此用户（或外部调度程序）必须明确触发其创建。 Flink也不会自动清理保存点。 第10章介绍如何触发和处置保存点。

#### 使用保存点
给定应用程序和兼容的保存点，您可以从保存点启动应用程序。 这会将应用程序的状态初始化为保存点的状态，并从保存点的运行点开始运行应用程序。 虽然此行为似乎与使用检查点从故障中恢复应用程序完全相同，但故障恢复实际上只是一种特殊情况。 它在同一群集上以相同的配置启动相同的应用程序。 从保存点启动应用程序可以让您做更多事情。
+ 您可以从保存点启动不同但兼容的应用程序。 因此，您可以修复应用程序逻辑中的错误，并重新处理流式源可以提供的任意数量的事件，以便修复结果。 修改后的应用程序还可用于运行A / B测试或具有不同业务逻辑的假设情景。 请注意，应用程序和保存点必须兼容 - 应用程序必须能够加载保存点的状态。
+ 您可以使用不同的并行性启动相同的应用程序，并将应用程序扩展或缩小。
+ 您可以在其他群集上启动相同的应用程序。 这允许您将应用程序迁移到较新的Flink版本或不同的群集或数据中心。
+ 您可以使用保存点暂停应用程序并稍后恢复。 这样就可以为更高优先级的应用程序释放集群资源，或者在不连续生成输入数据时释放集群资源。
+ 您还可以将保存点用于版本控制或并归档应用程序的状态。
由于保存点是如此强大的功能，许多用户会定期创建保存点以便能够及时返回。 我们看到最直接的操作是通过保存点不断将流应用程序迁移到提供最低实例价格的数据中心。

#### 从保存点申请应用
前面提到的保存点的所有用例都遵循相同的模式。 首先，获取正在运行的应用程序的保存点，然后将其用于恢复启动应用程序中的状态。 在本节中，我们将描述Flink如何初始化从保存点启动的应用程序的状态。

应用程序由多个运算符组成。 每个操作符可以定义一个或多个键控和操作状态。 操作符由一个或多个操作符任务并行执行。 因此，典型的应用程序包含多个状态，这些状态分布在可以在不同的TaskManager进程上运行的多个操作符任务中。

图3-26显示了一个具有三个运算符的应用程序，每个运算符运行两个任务 一个操作算子（OP-1）具有单个操作符状态（OS-1），而另一个操作算子（OP-2）具有两个键控状态（KS-1和KS-2）。 获取保存点时，会将所有任务的状态复制到持久存储位置。
![](https://github.com/alanzhang211/books/raw/master/%E5%A4%A7%E6%95%B0%E6%8D%AE/steaming-system/Stream%20Processing%20with%20Apache%20Flink/img/ch03/image-26.png)

保存点中的状态副本由操作员标识符和状态名称组织。 运算符标识符和状态名称需要能够将保存点的状态数据映射到启动应用程序的运算符的状态。 从保存点启动应用程序时，Flink会将保存点数据重新分配给相应运算符的任务。

> 请注意，保存点不包含有关操作符任务的信息。 这是因为当应用程序以不同的并行性启动时，任务数可能会更改。 我们在本节前面讨论过Flink的扩展有状态运算符的策略。
如果一个被修改的应用程序从保存点启动，则保存点中的状态只能映射到应用程序（如果它包含具有相应标识符和状态名称的运算符）。 默认情况下，Flink分配唯一的操作符标识符。 然而，基于其先前运算符的标识符确定性地生成运算符的标识符。 因此，操作符的标识符在其前任之一改变时改变，例如，当添加或移除操作符时。 因此，具有默认操作符标识符的应用程序在如何进化而不会丢失状态方面非常有限。 因此，我们强烈建议您为操作符手动分配唯一标识符，而不是依赖Flink的默认分配。 我们将在“指定唯一运算符标识符”中详细说明如何分配运算符标识符。

# 总结
在本章中，我们讨论了Flink的高级体系结构及其网络堆栈，事件处理模式，状态管理和故障恢复机制的内部结构。 在设计高级流应用程序，设置和配置群集，运行流应用程序以及推断其性能时，此信息将派上用场。
